import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, r2_score, accuracy_score
import plotly.graph_objects as go
import warnings
warnings.filterwarnings('ignore')

class PredictiveAnalyzer:
    """MÃ³dulo de anÃ¡lise preditiva avanÃ§ada"""
    
    def analyze(self, data, target_column, feature_columns, forecast_periods=6, ai_core=None):
        """Executa anÃ¡lise preditiva robusta"""
        try:
            # Preparar dados
            X = data[feature_columns].copy()
            y = data[target_column].copy()
            
            # Lidar com valores missing
            mask = ~(X.isna().any(axis=1) | y.isna())
            X = X[mask]
            y = y[mask]
            
            if len(X) < 10:
                return {'error': 'Dados insuficientes para anÃ¡lise (mÃ­nimo 10 amostras)'}
            
            # Verificar se Ã© classificaÃ§Ã£o ou regressÃ£o
            is_classification = self._check_classification(y)
            
            if is_classification:
                return self._classification_analysis(X, y, feature_columns, target_column)
            else:
                return self._regression_analysis(X, y, feature_columns, target_column, forecast_periods, data)
            
        except Exception as e:
            return {'error': f'Erro na anÃ¡lise preditiva: {str(e)}'}

    def _check_classification(self, y):
        """Verifica se o problema Ã© de classificaÃ§Ã£o"""
        unique_values = y.nunique()
        return unique_values <= 10 and unique_values >= 2

    def _regression_analysis(self, X, y, feature_columns, target_column, forecast_periods, original_data):
        """AnÃ¡lise para problemas de regressÃ£o"""
        # Dividir dados
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )
        
        # Treinar modelo
        model = RandomForestRegressor(n_estimators=100, random_state=42)
        model.fit(X_train, y_train)
        
        # PrevisÃµes e mÃ©tricas
        y_pred = model.predict(X_test)
        mae = mean_absolute_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)
        
        # PrevisÃ£o futura
        last_data = X.iloc[-1:].values
        forecast = []
        confidence_intervals = []
        
        for i in range(forecast_periods):
            # Prever prÃ³ximo valor
            next_pred = model.predict(last_data)[0]
            forecast.append(next_pred)
            
            # Calcular intervalo de confianÃ§a
            predictions = []
            for tree in model.estimators_:
                pred = tree.predict(last_data)[0]
                predictions.append(pred)
            
            std = np.std(predictions)
            confidence_intervals.append(std)
            
            # Simular dados futuros
            last_data = last_data * (1 + np.random.normal(0.02, 0.01))
        
        # GrÃ¡fico
        fig = self._create_forecast_plot(original_data[target_column], forecast, confidence_intervals, target_column)
        
        # ImportÃ¢ncia das features
        feature_importance = dict(zip(feature_columns, model.feature_importances_))
        
        # Insights avanÃ§ados
        insights = self._generate_regression_insights(model, X, y, feature_importance, r2, mae, forecast)
        
        return {
            'accuracy': max(0, r2),
            'mae': mae,
            'forecast': forecast,
            'confidence_intervals': confidence_intervals,
            'feature_importance': feature_importance,
            'forecast_plot': fig,
            'insights': insights,
            'model_type': 'regressÃ£o',
            'confidence': min(0.95, max(0, r2) + 0.1)
        }

    def _classification_analysis(self, X, y, feature_columns, target_column):
        """AnÃ¡lise para problemas de classificaÃ§Ã£o"""
        # Dividir dados
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
        
        # Treinar modelo
        model = RandomForestClassifier(n_estimators=100, random_state=42)
        model.fit(X_train, y_train)
        
        # PrevisÃµes e mÃ©tricas
        y_pred = model.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        
        # ImportÃ¢ncia das features
        feature_importance = dict(zip(feature_columns, model.feature_importances_))
        
        # Matriz de confusÃ£o (simplificada)
        confusion_info = self._get_confusion_info(y_test, y_pred)
        
        # Insights
        insights = self._generate_classification_insights(model, X, y, feature_importance, accuracy, confusion_info)
        
        return {
            'accuracy': accuracy,
            'feature_importance': feature_importance,
            'confusion_info': confusion_info,
            'insights': insights,
            'model_type': 'classificaÃ§Ã£o',
            'confidence': min(0.95, accuracy + 0.1)
        }

    def _create_forecast_plot(self, historical, forecast, confidence_intervals, target_name):
        """Cria grÃ¡fico de previsÃ£o com intervalo de confianÃ§a"""
        historical_periods = list(range(len(historical)))
        forecast_periods = list(range(len(historical), len(historical) + len(forecast)))
        
        fig = go.Figure()
        
        # HistÃ³rico
        fig.add_trace(go.Scatter(
            x=historical_periods,
            y=historical.values,
            mode='lines+markers',
            name='HistÃ³rico',
            line=dict(color='blue', width=3)
        ))
        
        # PrevisÃ£o
        fig.add_trace(go.Scatter(
            x=forecast_periods,
            y=[historical.iloc[-1]] + forecast,
            mode='lines+markers',
            name='PrevisÃ£o',
            line=dict(color='red', width=3, dash='dash')
        ))
        
        # Intervalo de confianÃ§a
        upper_bound = [historical.iloc[-1]] + [forecast[i] + confidence_intervals[i] for i in range(len(forecast))]
        lower_bound = [historical.iloc[-1]] + [forecast[i] - confidence_intervals[i] for i in range(len(forecast))]
        
        fig.add_trace(go.Scatter(
            x=forecast_periods,
            y=upper_bound,
            mode='lines',
            line=dict(width=0),
            showlegend=False
        ))
        
        fig.add_trace(go.Scatter(
            x=forecast_periods,
            y=lower_bound,
            mode='lines',
            line=dict(width=0),
            fillcolor='rgba(255, 0, 0, 0.2)',
            fill='tonexty',
            showlegend=False
        ))
        
        fig.update_layout(
            title=f"PrevisÃ£o - {target_name}",
            xaxis_title="PerÃ­odos",
            yaxis_title=target_name,
            showlegend=True
        )
        
        return fig

    def _get_confusion_info(self, y_true, y_pred):
        """InformaÃ§Ãµes da matriz de confusÃ£o"""
        from sklearn.metrics import classification_report, confusion_matrix
        cm = confusion_matrix(y_true, y_pred)
        report = classification_report(y_true, y_pred, output_dict=True)
        
        return {
            'confusion_matrix': cm.tolist(),
            'precision': report['weighted avg']['precision'],
            'recall': report['weighted avg']['recall'],
            'f1_score': report['weighted avg']['f1-score']
        }

    def _generate_regression_insights(self, model, X, y, feature_importance, r2, mae, forecast):
        """Gera insights para regressÃ£o"""
        insights = []
        
        # Insight de precisÃ£o
        if r2 > 0.8:
            insights.append("ğŸ¯ Modelo altamente preciso - confiÃ¡vel para decisÃµes")
        elif r2 > 0.6:
            insights.append("ğŸ“ˆ Boa precisÃ£o - adequado para planejamento")
        else:
            insights.append("âš ï¸ PrecisÃ£o moderada - considere mais variÃ¡veis")
        
        # Insight de tendÃªncia
        trend = "positiva" if np.mean(forecast) > y.iloc[-1] else "negativa"
        insights.append(f"ğŸ“Š TendÃªncia {trend} identificada")
        
        # Insight de variÃ¡veis importantes
        top_feature = max(feature_importance, key=feature_importance.get)
        insights.append(f"ğŸ” VariÃ¡vel mais influente: {top_feature}")
        
        # Insight de erro
        insights.append(f"ğŸ“ Erro mÃ©dio de {mae:.2f} unidades")
        
        return insights

    def _generate_classification_insights(self, model, X, y, feature_importance, accuracy, confusion_info):
        """Gera insights para classificaÃ§Ã£o"""
        insights = []
        
        # Insight de precisÃ£o
        if accuracy > 0.9:
            insights.append("ğŸ¯ ClassificaÃ§Ã£o excelente - altamente confiÃ¡vel")
        elif accuracy > 0.7:
            insights.append("ğŸ“Š Boa precisÃ£o - adequada para uso")
        else:
            insights.append("âš ï¸ PrecisÃ£o moderada - avalie cuidadosamente")
        
        # Insight de variÃ¡veis importantes
        top_feature = max(feature_importance, key=feature_importance.get)
        insights.append(f"ğŸ” Fator mais determinante: {top_feature}")
        
        # Insight de mÃ©tricas
        insights.append(f"ğŸ“ˆ PrecisÃ£o: {accuracy:.1%}")
        insights.append(f"ğŸ¯ F1-Score: {confusion_info['f1_score']:.1%}")
        
        return insights

    def quick_analyze(self, data, target_column):
        """AnÃ¡lise rÃ¡pida automÃ¡tica"""
        numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()
        feature_cols = [col for col in numeric_cols if col != target_column]
        
        if len(feature_cols) == 0:
            return {'error': 'VariÃ¡veis insuficientes para anÃ¡lise'}
        
        return self.analyze(data, target_column, feature_cols[:3], 3)
